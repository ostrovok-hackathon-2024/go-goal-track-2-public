{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./.venv/lib/python3.12/site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.venv/lib/python3.12/site-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: optuna in ./.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.12/site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in ./.venv/lib/python3.12/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.venv/lib/python3.12/site-packages (from optuna) (2.0.35)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.12/site-packages (0.3.9)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (6.0.0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install optuna\n",
    "!pip install dill\n",
    "!pip install psutil\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "categories = ['class', 'quality', 'bathroom', 'bedding', 'capacity', 'club', 'bedrooms', 'balcony', 'view', 'floor']\n",
    "models_dir = 'models_20240929_132912'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models_20240929_132912/label_encoder_class.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     label_encoders[category] \u001b[38;5;241m=\u001b[39m le\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_encoder_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcategory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Golang/Go-Goal-Track-2/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models_20240929_132912/label_encoder_class.npy'"
     ]
    }
   ],
   "source": [
    "#! THIS CODE DOES NOT WORK. CREATES BAD NPY FILES\n",
    "\n",
    "df = pd.read_csv('rates_clean.csv')\n",
    "df = df.fillna('undefined')\n",
    "\n",
    "\n",
    "for cat in categories:\n",
    "    df[cat] = df[cat].astype(str)\n",
    "\n",
    "# Convert 'rate_name' to string type\n",
    "df['rate_name'] = df['rate_name'].astype(str)\n",
    "\n",
    "X = df[['rate_name']]  # Keep as DataFrame\n",
    "y = df[categories]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "label_encoders = {}\n",
    "for category in categories:\n",
    "    le = LabelEncoder()\n",
    "    y_train[category] = le.fit_transform(y_train[category])\n",
    "    y_test[category] = le.transform(y_test[category])\n",
    "    label_encoders[category] = le\n",
    "\n",
    "for category in categories:\n",
    "    np.save(os.path.join(models_dir, f\"label_encoder_{category}.npy\"), le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 1.6676299572 seconds\n",
      "Batch execution time:\n",
      "Average iteration time: 53.7945 ms\n",
      "Maximum iteration time: 73.3070 ms\n",
      "Minimum iteration time: 21.0950 ms\n",
      "Avg iterationtime per 1 prediction: 8.9658 µs\n",
      "\n",
      "Results have been saved to classified_rates.csv\n",
      "\n",
      "First few rows of the results:\n",
      "                                   rate_name  class    quality  \\\n",
      "0    Standard - Double Room - With Breakfast   room   standard   \n",
      "1  6 Bed Non AC Mixed Dorm (1 Twin Bunk Bed)   dorm  undefined   \n",
      "2             Standard Twin Room non-smoking   room   standard   \n",
      "3    Deluxe Suite, Single or Double/Twin Bed  suite     deluxe   \n",
      "4                 King Premium Mountain View   room    premium   \n",
      "\n",
      "           bathroom                bedding   capacity      club   bedrooms  \\\n",
      "0  private bathroom  double/double-or-twin     double  not club  undefined   \n",
      "1   shared bathroom              undefined     double  not club  undefined   \n",
      "2  private bathroom    twin/twin-or-double     double  not club  undefined   \n",
      "3  private bathroom  double/double-or-twin     double  not club  undefined   \n",
      "4  private bathroom              undefined  undefined  not club  undefined   \n",
      "\n",
      "      balcony           view      floor  \n",
      "0  no balcony      undefined  undefined  \n",
      "1  no balcony      undefined  undefined  \n",
      "2  no balcony      undefined  undefined  \n",
      "3  no balcony      undefined  undefined  \n",
      "4  no balcony  mountain view  undefined  \n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "label_encoders = {}\n",
    "\n",
    "for category in categories:\n",
    "    model_path = os.path.join(models_dir, f\"catboost_model_{category}.cbm\")\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(model_path)\n",
    "    models[category] = model\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.classes_ = np.load(os.path.join(models_dir, f\"label_encoder_{category}.npy\"), allow_pickle=True)\n",
    "    label_encoders[category] = le\n",
    "\n",
    "\n",
    "def preprocess_input(input_strings):\n",
    "    # Convert input strings to a DataFrame\n",
    "    df = pd.DataFrame({'rate_name': input_strings})\n",
    "    \n",
    "    # Apply the same preprocessing as during training\n",
    "    df['rate_name'] = df['rate_name'].astype(str)\n",
    "    \n",
    "    # Return the preprocessed DataFrame\n",
    "    return df\n",
    "\n",
    "def run_batch_prediction(model, label_encoder, input_strings):\n",
    "    # Preprocess the input\n",
    "    input_data = preprocess_input(input_strings)\n",
    "    \n",
    "    # Predict probabilities for the entire batch\n",
    "    predictions = model.predict_proba(input_data)\n",
    "    \n",
    "    # Get the indices of the highest probabilities\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    \n",
    "    # Use the indices directly with classes_ for faster inverse transform\n",
    "    return label_encoder.classes_[predicted_classes]\n",
    "\n",
    "def classify_rates(rate_names: list) -> list:\n",
    "    classifications = {category: run_batch_prediction(models[category], label_encoders[category], rate_names) \n",
    "                       for category in categories}\n",
    "    return [dict(zip(categories, [classifications[cat][i] for cat in categories])) \n",
    "            for i in range(len(rate_names))]\n",
    "\n",
    "df_dirty = pd.read_csv('rates_dirty.csv')\n",
    "df_dirty = df_dirty.fillna('undefined')\n",
    "\n",
    "\n",
    "batch_size = 6000  # нет смысла ставить больше 6000, так как после 5500 маленький прирост\n",
    "results = []\n",
    "benchmark_results = []\n",
    "total_time = 0\n",
    "\n",
    "for i in range(0, len(df_dirty), batch_size):\n",
    "    batch = df_dirty.iloc[i:i+batch_size]\n",
    "    rate_names = batch['rate_name'].tolist()\n",
    "    \n",
    "    iteration_start_time = time.time()\n",
    "    batch_classifications = classify_rates(rate_names)\n",
    "    iteration_end_time = time.time()\n",
    "    \n",
    "    iteration_time = iteration_end_time - iteration_start_time\n",
    "    total_time += iteration_time\n",
    "    benchmark_results.append({\n",
    "        'batch_size': len(batch),\n",
    "        'iteration_time': iteration_time,\n",
    "    })\n",
    "    \n",
    "    for rate_name, classifications in zip(rate_names, batch_classifications):\n",
    "        results.append({\n",
    "            'rate_name': rate_name,\n",
    "            **classifications\n",
    "        })\n",
    "\n",
    "print(f\"Total time taken: {total_time:.10f} seconds\")\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_benchmark = pd.DataFrame(benchmark_results)\n",
    "\n",
    "avg_iteration_time = df_benchmark['iteration_time'].mean()\n",
    "max_iteration_time = df_benchmark['iteration_time'].max()\n",
    "min_iteration_time = df_benchmark['iteration_time'].min()\n",
    "\n",
    "print(f\"Batch execution time:\")\n",
    "print(f\"Average iteration time: {avg_iteration_time * 1000:.4f} ms\")\n",
    "print(f\"Maximum iteration time: {max_iteration_time * 1000:.4f} ms\")\n",
    "print(f\"Minimum iteration time: {min_iteration_time * 1000:.4f} ms\")\n",
    "print(f\"Avg iterationtime per 1 prediction: {avg_iteration_time / batch_size * 1e6:.4f} µs\")\n",
    "\n",
    "output_file = 'classified_rates.csv'\n",
    "df_results.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nResults have been saved to {output_file}\")\n",
    "\n",
    "print(\"\\nFirst few rows of the results:\")\n",
    "print(df_results[['rate_name'] + categories].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall error rate: 0.15\n",
      "Total rows: 180443\n",
      "Rows with errors: 26405\n",
      "\n",
      "Column Error Statistics:\n",
      "Column 5 (capacity): Error rate = 0.07, Errors = 12260\n",
      "Column 9 (view): Error rate = 0.04, Errors = 6419\n",
      "Column 3 (bathroom): Error rate = 0.01, Errors = 2700\n",
      "Column 2 (quality): Error rate = 0.04, Errors = 7434\n",
      "Column 1 (class): Error rate = 0.02, Errors = 4011\n",
      "Column 4 (bedding): Error rate = 0.05, Errors = 9139\n",
      "Column 6 (club): Error rate = 0.01, Errors = 1907\n",
      "Column 7 (bedrooms): Error rate = 0.01, Errors = 2439\n",
      "Column 10 (floor): Error rate = 0.01, Errors = 2138\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def compare_csv_files(file1_path, file2_path, threshold=0.8):\n",
    "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
    "        reader1 = csv.reader(file1)\n",
    "        reader2 = csv.reader(file2)\n",
    "        \n",
    "        header1 = next(reader1)\n",
    "        header2 = next(reader2)\n",
    "        \n",
    "        if header1 != header2:\n",
    "            print(\"Warning: Headers do not match\")\n",
    "        \n",
    "        total_rows = 0\n",
    "        error_rows = 0\n",
    "        column_errors = defaultdict(int)\n",
    "        \n",
    "        for row1, row2 in zip(reader1, reader2):\n",
    "            # Replace \"undefined\" with empty string\n",
    "            row1 = ['' if val == 'undefined' else val for val in row1]\n",
    "            row2 = ['' if val == 'undefined' else val for val in row2]\n",
    "\n",
    "            total_rows += 1\n",
    "            row_errors = 0\n",
    "            \n",
    "            for i, (val1, val2) in enumerate(zip(row1, row2)):\n",
    "                similarity = calculate_similarity(val1, val2)\n",
    "                if similarity < threshold:\n",
    "                    row_errors += 1\n",
    "                    column_errors[i] += 1\n",
    "            \n",
    "            error_rate = row_errors / len(row1)\n",
    "            if error_rate > 0:\n",
    "                error_rows += 1\n",
    "                # print(f\"Row {total_rows}: Error rate = {error_rate:.2f}\")\n",
    "                # print(f\"Row {total_rows}: {row1} - {row2}\")\n",
    "        \n",
    "        overall_error_rate = error_rows / total_rows\n",
    "        print(f\"\\nOverall error rate: {overall_error_rate:.2f}\")\n",
    "        print(f\"Total rows: {total_rows}\")\n",
    "        print(f\"Rows with errors: {error_rows}\")\n",
    "        \n",
    "        print(\"\\nColumn Error Statistics:\")\n",
    "        for i, error_count in column_errors.items():\n",
    "            column_error_rate = error_count / total_rows\n",
    "            print(f\"Column {i} ({header1[i]}): Error rate = {column_error_rate:.2f}, Errors = {error_count}\")\n",
    "\n",
    "# Usage\n",
    "file1_path = 'classified_rates.csv'\n",
    "file2_path = 'rates_dirty.csv'\n",
    "compare_csv_files(file1_path, file2_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
